{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02402b31-b4b9-43ed-8708-1fa87c5fd7b3",
   "metadata": {},
   "source": [
    "# Project 7.1.1 Fashion mnist with convents and in-model scaling and augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf0a296-4d7d-4901-8b33-0c8a717c0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Desktop\\programowanie_web_etc\\python_projects\\ml_zoo\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3159dbc7-cb36-4d60-a9ff-61d9417cc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bb3f81-a1cf-4859-a44f-38b8657ad4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea5cf47-e538-4882-93d8-17937b897d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6b61d4a-054a-4bb1-a659-0a0f0bf2f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Rescaling(1./255),\n",
    "    layers.RandomFlip(),\n",
    "    layers.RandomRotation(factor=(-0.2, 0, 0.3)),\n",
    "    layers.Conv2D(filters=32,  kernel_size = 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(filters=32,  kernel_size = 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(num_classes),\n",
    "    layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fed1d8c-ee3a-40b2-bf3c-7e2177d19822",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c0dac4d-66ee-4abd-b7cc-ce7d3147f242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(train_images,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5c653a5-004d-4b9f-b368-2eabba5764be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4418 - accuracy: 0.8403 - val_loss: 0.6073 - val_accuracy: 0.7905\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4337 - accuracy: 0.8442 - val_loss: 0.6279 - val_accuracy: 0.7880\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4270 - accuracy: 0.8447 - val_loss: 0.6020 - val_accuracy: 0.7897\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4240 - accuracy: 0.8474 - val_loss: 0.5629 - val_accuracy: 0.8073\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4170 - accuracy: 0.8495 - val_loss: 0.5796 - val_accuracy: 0.8030\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4131 - accuracy: 0.8506 - val_loss: 0.5871 - val_accuracy: 0.7979\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4101 - accuracy: 0.8524 - val_loss: 0.6016 - val_accuracy: 0.7925\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4073 - accuracy: 0.8536 - val_loss: 0.5626 - val_accuracy: 0.8070\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4011 - accuracy: 0.8571 - val_loss: 0.5746 - val_accuracy: 0.8013\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3988 - accuracy: 0.8563 - val_loss: 0.5739 - val_accuracy: 0.8055\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  np.expand_dims(train_images,-1), train_labels,\n",
    "  validation_data=(np.expand_dims(test_images,-1), test_labels),\n",
    "  epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa4fc535-423a-4093-8293-5b6dc8e4d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = test_images[43]\n",
    "img = np.expand_dims(img, 0)\n",
    "img = np.expand_dims(img, -1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6726b164-0f0f-4a1f-8483-ee2c1a985a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c0fa7bb-2d8d-4dc7-a687-0a66b65b14d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed623f1b-b133-4478-80dc-5cb7983dcad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_model = tf.keras.Sequential([\n",
    "#     model,\n",
    "#     layers.Softmax()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f301470b-c37e-4a0b-9e90-68b1bbbc734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = prediction_model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b852a073-e759-476a-905a-3fda33791322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c3234-4381-4f8e-b344-b888b34bfe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_zoo_venv",
   "language": "python",
   "name": "ml_zoo_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
