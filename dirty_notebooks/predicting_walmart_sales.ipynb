{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "698e761f-e6c2-49e8-8253-57420f00a93d",
   "metadata": {},
   "source": [
    "### Project 1. Predicting Walmart Sales\n",
    "\n",
    "Predicting the weekly sales of 45 different Walmart Stores, based on data from 2010 - 2012.\n",
    "The factors considered include:\n",
    "* The average air temperature in the region\n",
    "* The cost of fuel in the region\n",
    "* That week's consumer price index\n",
    "* The unemployment rate in the region\n",
    "* Whether a holiday occured in that week\n",
    "* (engineered) the month the week happened in\n",
    "* (engineered) the week's number within the month\n",
    "\n",
    "The main goal of this project is to predict the weekly sales of any of the Walmart stores considered, using regression models, but, an additional task could involve the prediction of the store based on the sales and other factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91a86c-6097-4758-b938-8b9ff6956cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720f6ef-1469-49b1-97c0-041a242a1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715e9f3-eed6-4e88-9d1c-63a883f9ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path  = '../datasets/walmart_sales.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20c5ea7-afe1-49ea-b7b4-105cb7e3ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ac177-ece8-4b50-87aa-620c610b2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3098353-bd6c-4be8-aa3e-718e69487654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bee44-75ac-4a24-8822-31e051520219",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check for nulls - None found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7cdc6-ed31-44e5-b9b3-cbb034d13299",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2b349-fee1-4f9a-b633-4b8ccebfe7a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Let's uniform the columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b32f9-f729-466c-8d3d-d627b89eff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = list(map(lambda col: col.lower().replace(' ', '_'), df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0bde55-925e-4f23-98b3-11d0cfe3d61e",
   "metadata": {},
   "source": [
    "### General data stats - distributions, scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89176024-4409-4b1f-99f1-077e7e3eb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec437c-7104-4468-a58f-98416be0a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_fig = make_subplots(rows = 6, cols = 2,\n",
    "                        subplot_titles=(\"Store number\", \"Is holiday?\",\n",
    "                                        \"Weekly sales\",\n",
    "                                        \"Temperature\",\n",
    "                                        \"Fuel price\",\n",
    "                                        \"CPI\",\n",
    "                                        \"Unemployment\"),\n",
    "                        specs = [\n",
    "                            [{}, {}],\n",
    "                            [{\"colspan\": 2}, None],\n",
    "                            [{\"colspan\": 2}, None],\n",
    "                            [{\"colspan\": 2}, None],\n",
    "                            [{\"colspan\": 2}, None],\n",
    "                            [{\"colspan\": 2}, None],\n",
    "                        ],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6624e-b106-4fae-8c28-8f54f9ddc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['store']),\n",
    "    row=1, col=1\n",
    ")\n",
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['holiday_flag']),\n",
    "    row=1, col=2\n",
    ")\n",
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['weekly_sales']),\n",
    "    row=2, col=1\n",
    ")\n",
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['temperature']),\n",
    "    row=3, col=1\n",
    ")\n",
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['fuel_price']),\n",
    "    row=4, col=1\n",
    ")\n",
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['cpi']),\n",
    "    row=5, col=1\n",
    ")\n",
    "hist_fig.add_trace(\n",
    "    go.Histogram(x=df['unemployment']),\n",
    "    row=6, col=1\n",
    ")\n",
    "\n",
    "hist_fig.update_layout(height = 1000, width = 1200)\n",
    "# hist_fig.update_layout(autosize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1520b101-e44d-4c21-8f5f-097a5cc7baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_fig = px.scatter_matrix(df)\n",
    "scatter_fig.update_layout(height = 1200, width = 1200)\n",
    "scatter_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548aee5-69a3-4a76-88ea-a918dc25617a",
   "metadata": {},
   "source": [
    "It's rather high to make any substantial claims about any factor's relation to our predicted variable (weekly sales). No clear linear trends appear.  \n",
    "Still, the distribution plots appear more promising, with a healthy amount of variance and not a lot of extreme values for  any of the factors.  \n",
    "The only possibly suspicious distribution is that of the consumer price index, with a clear distribution split, implying either a change in how it is calculated at some point in time, a sudden change in the US Dollar's value or some other event, which may not fare well for the model's generalizational skills. Nevertheless, it will initially be considrered as one of the factors to include in the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc114772-80a3-402a-9623-a1fb30444af3",
   "metadata": {},
   "source": [
    "### Datatype cleanup, extra feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb6648-d01b-4d63-9f83-051414e79706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de721ef9-274c-4d6c-9695-9fb615dc2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format=\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f4488-e681-4526-b2a5-5bacfac8ddcf",
   "metadata": {},
   "source": [
    "### Extra features - week number, month, week of month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240401f-3d12-4d1c-81ee-9bd4f02a6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week_number'] = df['date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ef148-83b4-4539-b2b9-9dd1e27f9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148a885-ada9-499a-a1fc-fe6dcb645cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week_of_month'] = df.apply(\n",
    "    lambda row: pendulum.parse(row['date'].strftime('%Y-%m-%d')).week_of_month,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08f273-9310-4e4f-834d-408db8632e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week_of_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60313622-2f4c-4029-814c-b8b9072d9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_fig_week = px.scatter_matrix(df,\n",
    "                                 dimensions = ['week_number', 'month', 'week_of_month', 'weekly_sales'])\n",
    "scatter_fig_week.update_layout(height = 1000, width = 1000)\n",
    "scatter_fig_week.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b10268-11e5-4343-8bff-c20bd5098a35",
   "metadata": {},
   "source": [
    "It would seem that typically week 4 is the big spender week in many of the stores. A similar rise can be ovserved in months 11 and 12 (november and december), which include both Thanksgiving Day and Christmas Holidays, which can drive up sales. Worth considering is also the following january fall in sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e5ecc-b1f5-4fe1-9fc5-eca1d41f596a",
   "metadata": {},
   "source": [
    "### Extra features: previous week's sales, temperature, fuel price, did the previous week include a holiday and the differences between current week and last week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cbe9c-ddcb-4187-8d44-ee859603eb6e",
   "metadata": {},
   "source": [
    "#### Get previous week's values for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c9217-f36d-4d99-84f7-2694ced862ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_weekly_sales'] = df.sort_values(['store','date']).groupby(['store'])['weekly_sales'].shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdbc12-8792-4d1c-b8b8-df5e6dee3303",
   "metadata": {},
   "source": [
    "#### Fill first week of data for each store with current value instead of 0 or leaving a NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbb167-f165-458c-9ccc-f716229b43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_weekly_sales'] = df['prev_weekly_sales'].fillna(df['weekly_sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff466961-f1d3-4c4c-98e0-dfb3ef51c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_temperature'] = df.sort_values(['store','date']).groupby(['store'])['temperature'].shift()\n",
    "df['prev_fuel_price'] = df.sort_values(['store','date']).groupby(['store'])['fuel_price'].shift()\n",
    "df['prev_cpi'] = df.sort_values(['store','date']).groupby(['store'])['cpi'].shift()\n",
    "df['prev_unemployment'] = df.sort_values(['store','date']).groupby(['store'])['unemployment'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0528d-2d41-467a-a837-f285598f64ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_temperature'] = df['prev_temperature'].fillna(df['temperature'])\n",
    "df['prev_fuel_price'] = df['prev_fuel_price'].fillna(df['fuel_price'])\n",
    "df['prev_cpi'] = df['prev_cpi'].fillna(df['cpi'])\n",
    "df['prev_unemployment'] = df['prev_unemployment'].fillna(df['unemployment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d65be1-e850-4921-a62f-ad4a79017cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0ca6b-2a38-46e9-9ab2-fb7b8e7f9a2b",
   "metadata": {},
   "source": [
    "#### Calculate differences from previous week to current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d5493-38df-4d69-80c8-3d4bd04d1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cols = ['weekly_sales', 'temperature', 'fuel_price', 'cpi', 'unemployment', 'holiday_flag']\n",
    "for col in prev_cols:\n",
    "    df[f'{col}_diff'] = df[f'{col}'] - df[f'prev_{col}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b566e8-aed6-4a49-8c0f-79a9b01495bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_holiday_flag'] = df.sort_values(['store','date']).groupby(['store'])['holiday_flag'].shift()\n",
    "df['prev_holiday_flag'] = df['prev_holiday_flag'].fillna(df['holiday_flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c59a2-0e00-4bf5-9171-162df595ef16",
   "metadata": {},
   "source": [
    "##### previous month, week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746d595-615a-48f5-8190-f519f03ebc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prev_month'] = df.sort_values(['store','date']).groupby(['store'])['month'].shift()\n",
    "df['prev_month'] = df['prev_month'].fillna(df['month'])\n",
    "df['prev_week_number'] = df.sort_values(['store','date']).groupby(['store'])['week_number'].shift()\n",
    "df['prev_week_number'] = df['prev_week_number'].fillna(df['week_number'])\n",
    "df['prev_week_of_month'] = df.sort_values(['store','date']).groupby(['store'])['week_of_month'].shift()\n",
    "df['prev_week_of_month'] = df['prev_week_of_month'].fillna(df['week_of_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf03482-bd9b-4c28-91b1-5a9eb9e1a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f287d3d-3adb-4f9a-b6f5-9a2712901909",
   "metadata": {},
   "source": [
    "### Scatter plot between calculated features and weekly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13f989-781e-49ff-9171-3516e9227ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_2_cols = [f'prev_{col}' for col in prev_cols]\n",
    "# + [f'{col}_diff' for col in prev_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2bcd0a-baee-46d5-b9f1-fcc69fe471a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_2_cols.append('weekly_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed9be8-47b7-4a2d-a1fe-b63876bf2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_fig_2 = px.scatter_matrix(df,\n",
    "                                 dimensions = scatter_2_cols)\n",
    "scatter_fig_2.update_layout(height = 1400, width = 1400)\n",
    "scatter_fig_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7ac21-f0e4-4d78-a650-912ce31c00ef",
   "metadata": {},
   "source": [
    "### Let's try a first quick model, firstly without the extracted shifted / previou week features, then with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388d174-b586-4741-9106-b8aa5a3d0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21176c-96de-4c0e-a74b-0d3ef45fe99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure = df[['holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment', 'week_number', 'month',\n",
    "       'week_of_month']]\n",
    "y_pure = df[['weekly_sales']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b70968-52c9-4437-b453-b654f7611855",
   "metadata": {},
   "source": [
    "#### Let's start with simple decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc943ce-ba77-4264-be82-dec3b6c48f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fdce9-589f-47e5-9791-83ecd57bf6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25299d-ff5e-4cf9-8910-a9aa0093355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839126d4-8afe-408c-ad03-192613d59c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pure_train, X_pure_test, y_pure_train, y_pure_test = train_test_split(X_pure, y_pure, shuffle=True, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818664f-0845-4c9f-b686-9127b1f9c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_pure = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f220a-8afd-47d1-b96a-aabb78302b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model_pure.fit(X_pure_train, y_pure_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c66b5-5329-40eb-91e6-b499d198d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pure_preds = tree_model_pure.predict(X_pure_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f792085-3810-4ca1-93e0-53a77c550c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pure_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd286f9b-a7c8-4555-a191-aeeedc54777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pure_error = mean_absolute_error(y_pure_test, tree_pure_preds)\n",
    "tree_pure_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6fe3c-37bc-46be-a390-0b2472c34a0e",
   "metadata": {},
   "source": [
    "#### Oof, a mean absolute error of over 440k\n",
    "Let's see how much that actually is, in the context of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf7f694-291b-4cc8-bedb-749f2e9b6f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sales = df['weekly_sales'].max()\n",
    "min_sales = df['weekly_sales'].min()\n",
    "avg_sales = df['weekly_sales'].mean()\n",
    "median_sales = df['weekly_sales'].median()\n",
    "sales_data = {'max': [max_sales], 'min': [min_sales], 'avg': [avg_sales], 'median': [median_sales]}\n",
    "sales_df = pd.DataFrame(sales_data, index=['tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e87e6-b8a4-4999-82c6-bc81264608ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['mae_error'] = round(tree_pure_error,2)\n",
    "sales_df['mae_by_max'] = round(sales_df['mae_error'] * 100 / sales_df['max'],2)\n",
    "sales_df['mae_by_min'] = round(sales_df['mae_error'] * 100 / sales_df['min'],2)\n",
    "sales_df['mae_by_avg'] = round(sales_df['mae_error'] *100 / sales_df['avg'],2)\n",
    "sales_df['mae_by_median'] = round(sales_df['mae_error'] * 100 / sales_df['median'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381952f-5768-4ffb-971f-1ba31d7aeada",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881938bc-f8f6-45a2-abc6-5c784e67f00f",
   "metadata": {},
   "source": [
    "### Basic decision tree with pure features results:\n",
    "As we can see, the mean error, reach as far as 42% of the mean sales value, making the trained model practically useless\n",
    "But - let's not get discouraged, as this is merely the first, extremely basic model we will look at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c5e1b-c64c-497d-ae8a-4f378da1da68",
   "metadata": {},
   "source": [
    "### Let's explore decision trees further, with different max number of leaf nodes\n",
    "As setting the maximum depth, will stop only at that depth, whilst choosing a maximum number of leaf nodes will try to optimize for best results and potentially drop some branches and reach a further overall depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd50dbb-75af-4418-9b93-92ba8fb40894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd6d97-ad50-4d95-8586-1a55a2694232",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pure_tree_mae = tree_pure_error\n",
    "for max_leaf_nodes in [5, 50, 200, 250, 350, 500, 1000, 1750, 2500, 5000]:\n",
    "    leaf_mae = get_tree_mae(max_leaf_nodes, X_pure_train, X_pure_test, y_pure_train, y_pure_test)\n",
    "    if leaf_mae < best_pure_tree_mae:\n",
    "        best_pure_tree_mae = leaf_mae\n",
    "    print(f'Max leaf nodes: {max_leaf_nodes}, MAE Error: {leaf_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402180b-8fc3-423b-899b-b3981c8047de",
   "metadata": {},
   "source": [
    "#### Under these parameters, the optional number of nodes lies somewhere about **200 max leaf nodes**\n",
    "as such, let's update our results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d3171-5315-418b-b8ff-09d85f943e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['mae_error'] = round(best_pure_tree_mae,2)\n",
    "sales_df['mae_by_max'] = round(sales_df['mae_error'] * 100 / sales_df['max'],2)\n",
    "sales_df['mae_by_min'] = round(sales_df['mae_error'] * 100 / sales_df['min'],2)\n",
    "sales_df['mae_by_avg'] = round(sales_df['mae_error'] *100 / sales_df['avg'],2)\n",
    "sales_df['mae_by_median'] = round(sales_df['mae_error'] * 100 / sales_df['median'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7544091-bcb9-4cdc-9bfd-d464d8d0e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea57216-1fb3-4cbf-af68-86613008472d",
   "metadata": {},
   "source": [
    "Still a third of the average sales - quite a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c352eb-a5b7-4786-8d68-64d273f0370b",
   "metadata": {},
   "source": [
    "### Let's look at random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd54e4-f8c1-49b5-95a2-b2c1853684d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestRegressor()\n",
    "random_forest_model.fit(X_pure_train, y_pure_train.values.ravel())\n",
    "random_forest_preds = random_forest_model.predict(X_pure_test)\n",
    "random_forest_mae = mean_absolute_error(y_pure_test, random_forest_preds)\n",
    "round(random_forest_mae,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6f8b8-7636-41d7-a099-1f9a665cbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_df = pd.DataFrame({'mae': [round(best_pure_tree_mae, 2)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43486adf-8f58-4c6b-97d1-ebe128b11d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1303789-648f-4d9a-b18e-e95a8591353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_df.index = ['tree_pure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd024466-e9d5-413d-a6f3-a3ee4977379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_df = pd.DataFrame([random_forest_mae], columns=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb20429-ea27-4453-97ab-a1014141ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_df.index = ['random_forest_pure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ad90a-1b83-4390-bc44-1a690537bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_df = pd.concat([maes_df, random_forest_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e137b5f-cb9a-4c43-b312-5947b4a4f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "maes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9824335-e7b4-410e-a1b6-923bfd5cba52",
   "metadata": {},
   "source": [
    "### With one model clearly better, let's try to explore different dataset feature choices, before going into further model choices or data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d45a09-4c73-48c1-968c-66962edfdabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3042fa-ddba-43c9-95e1-037682da130a",
   "metadata": {},
   "source": [
    "#### Let's first look at very broad feature ranges, potentially removing singular features later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405f761-b2f2-41ad-bb14-74dc05f19d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the base dataframe information the date\n",
    "df_noeng = df[['store', 'weekly_sales', 'holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment']]\n",
    "\n",
    "# the base dataframe information the date and store\n",
    "df_noeng_nostore = df[['weekly_sales', 'holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment']]\n",
    "\n",
    "# with additional information about week and month\n",
    "df_week = df[['weekly_sales', 'holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment', 'week_number', 'month',\n",
    "       'week_of_month']]\n",
    "\n",
    "# with additional information about week and month AND data about the previous week\n",
    "df_week_prev = df[['weekly_sales', 'holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment', 'week_number', 'month',\n",
    "       'week_of_month', 'prev_weekly_sales', 'prev_temperature',\n",
    "       'prev_fuel_price', 'prev_cpi', 'prev_unemployment', 'prev_month',\n",
    "       'prev_week_number', 'prev_week_of_month']]\n",
    "\n",
    "df_week_prev_diff = df[['weekly_sales', 'holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment', 'week_number', 'month',\n",
    "       'week_of_month', 'prev_weekly_sales', 'prev_temperature',\n",
    "       'prev_fuel_price', 'prev_cpi', 'prev_unemployment', 'weekly_sales_diff',\n",
    "       'temperature_diff', 'fuel_price_diff', 'cpi_diff', 'unemployment_diff',\n",
    "       'prev_holiday_flag', 'holiday_flag_diff', 'prev_month',\n",
    "       'prev_week_number', 'prev_week_of_month']]\n",
    "\n",
    "df_week_prev_diff_store = df[['store', 'weekly_sales', 'holiday_flag', 'temperature',\n",
    "       'fuel_price', 'cpi', 'unemployment', 'week_number', 'month',\n",
    "       'week_of_month', 'prev_weekly_sales', 'prev_temperature',\n",
    "       'prev_fuel_price', 'prev_cpi', 'prev_unemployment', 'weekly_sales_diff',\n",
    "       'temperature_diff', 'fuel_price_diff', 'cpi_diff', 'unemployment_diff',\n",
    "       'prev_holiday_flag', 'holiday_flag_diff', 'prev_month',\n",
    "       'prev_week_number', 'prev_week_of_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917144db-4a91-410c-a804-259feffaccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [df_noeng, df_noeng_nostore, df_week, df_week_prev, df_week_prev_diff, df_week_prev_diff_store]\n",
    "dataset_names = ['noeng', 'noeng_nostore', 'week', 'week_prev', 'week_prev_diff', 'week_prev_diff_store']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf5f9a-3cca-49c6-9559-615bc9a90903",
   "metadata": {},
   "source": [
    "### Function to assess datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d76a1b5-d82d-46e0-982b-0a209c5cba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_sales_dataset_tree(input_df):\n",
    "    input_X = input_df.drop(['weekly_sales'], axis=1)\n",
    "    input_y = input_df[['weekly_sales']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_X, input_y, shuffle=True, train_size=0.8)\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes = 200)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bd4d7-4d89-4a7a-9b41-c4a2fd3725f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what_mae = assess_sales_dataset_tree(df_noeng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00911aa-d60f-46d2-a1c2-cfb96c0d6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201be394-5b16-434f-b324-a7ceeae357e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tree_dataset_mae = df[['weekly_sales']].max().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071039b3-160a-416d-a53a-8a29bf0d49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tree_dataset_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78882c92-21cd-4342-b4ac-7d7ce2ff6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_dataset_mae = df[['weekly_sales']].max().values[0]\n",
    "for df_index, dataset in enumerate(datasets):\n",
    "    df_mae = assess_sales_dataset_tree(dataset)\n",
    "    if df_mae < best_tree_dataset_mae:\n",
    "        best_tree_dataset_mae = df_mae\n",
    "    print(f'df: {dataset_names[df_index]}, MAE Error: {df_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825b7fe-091a-4e61-afac-e404fcf356d1",
   "metadata": {},
   "source": [
    "### Clearly, using the previous week information yields the best results\n",
    "* What may be concerning though is how adding the week information by itself, made the results slightly worse\n",
    "* But what's also interesting is how the removal of the 'store' information, had terrible consequences. Perhaps it is unsurprising - information about which store you are considering will probably strongly influence the sales prediction, as can be seen in the weekly sales distribution, which has quite a large range. The question is - do we want to use this information, for most accurate results or do we want to ignore it, to make the model more general and applicable to any store not present in the dataset, but rather limiting ourselves to only data about the region such potential store would reside in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a231ee-765e-4535-81b3-130e5d95715f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_zoo_venv",
   "language": "python",
   "name": "ml_zoo_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
